{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nmodule 'keras' has no attribute 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1172\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1172\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[0;32m   1173\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1149\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations_tf\u001b[39;00m \u001b[39mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_tf_outputs\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     TFBaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m     29\u001b[0m     TFBaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     TFTokenClassifierOutput,\n\u001b[0;32m     37\u001b[0m )\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\transformers\\activations_tf.py:107\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mactivations\u001b[39m.\u001b[39mgelu(x, approximate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 107\u001b[0m gelu \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mactivations\u001b[39m.\u001b[39mgelu\n\u001b[0;32m    108\u001b[0m gelu_new \u001b[39m=\u001b[39m approximate_gelu_wrap\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:58\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, item):\n\u001b[1;32m---> 58\u001b[0m   module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load()\n\u001b[0;32m     59\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, item)\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[0;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\api\\__init__.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m module_wrapper \u001b[39mas\u001b[39;00m _module_wrapper\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\api\\keras\\__init__.py:15\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\api\\keras\\applications\\__init__.py:13\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m imagenet_utils\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m inception_resnet_v2\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m inception_v3\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\api\\keras\\applications\\inception_resnet_v2\\__init__.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minception_resnet_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m InceptionResNetV2\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minception_resnet_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m decode_predictions\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\applications\\__init__.py:41\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mefficientnet_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m EfficientNetV2S\n\u001b[1;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minception_resnet_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m InceptionResNetV2\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minception_v3\u001b[39;00m \u001b[39mimport\u001b[39;00m InceptionV3\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\applications\\inception_resnet_v2.py:324\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m--> 324\u001b[0m \u001b[39m@keras\u001b[39m\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39mregister_keras_serializable()\n\u001b[0;32m    325\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCustomScaleLayer\u001b[39;00m(keras_layers\u001b[39m.\u001b[39mLayer):\n\u001b[0;32m    326\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, scale, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras' has no attribute 'utils'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# modification\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m TFBertModel, BertTokenizer\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Input, Bidirectional, LSTM, Dense, Concatenate\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1231\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1163\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m   1162\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1163\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1162\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[0;32m   1161\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m-> 1162\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[0;32m   1163\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1164\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1174\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m   1173\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1175\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1176\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1177\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nmodule 'keras' has no attribute 'utils'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input[0][0]']                  \n",
      "                                thPoolingAndCrossAt                                               \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 100,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 128)          426496      ['tf_bert_model[0][0]']          \n",
      "                                                                                                  \n",
      " emotion_output (Dense)         (None, 7)            903         ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " concatenation_of_blstm_emotion  (None, 135)         0           ['bidirectional[0][0]',          \n",
      "  (Concatenate)                                                   'emotion_output[0][0]']         \n",
      "                                                                                                  \n",
      " sentiment_output (Dense)       (None, 3)            387         ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " toxicity_output (Dense)        (None, 7)            952         ['concatenation_of_blstm_emotion[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,910,978\n",
      "Trainable params: 109,910,978\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Constants\n",
    "MAX_SEQ_LEN = 100\n",
    "LSTM_UNITS = 64\n",
    "\n",
    "# Task-specific constants\n",
    "NUM_EMOTION_CLASSES = 7\n",
    "NUM_SENTIMENT_CLASSES = 3\n",
    "NUM_TOXICITY_CLASSES = 7\n",
    "\n",
    "# Initialize the BERT tokenizer and model\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Input and BERT layers\n",
    "input_layer = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name='input')\n",
    "bert_output = bert_model(input_layer)[0]  # Use index 0 to get the last-layer hidden states\n",
    "\n",
    "# Bidirectional LSTM layer\n",
    "bi_lstm_layer = Bidirectional(LSTM(LSTM_UNITS))(bert_output)\n",
    "\n",
    "# Task-specific layers\n",
    "emotion_output = Dense(NUM_EMOTION_CLASSES, activation='softmax', name='emotion_output')(bi_lstm_layer)\n",
    "sentiment_output = Dense(NUM_SENTIMENT_CLASSES, activation='softmax', name='sentiment_output')(bi_lstm_layer)\n",
    "toxicity_input = Concatenate(name=\"concatenation_of_blstm_emotion\")([bi_lstm_layer, emotion_output])\n",
    "toxicity_output = Dense(NUM_TOXICITY_CLASSES, activation='softmax', name='toxicity_output')(toxicity_input)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_layer, outputs=[emotion_output, sentiment_output, toxicity_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'emotion_output': 'categorical_crossentropy',\n",
    "        'sentiment_output': 'categorical_crossentropy',\n",
    "        'toxicity_output': 'categorical_crossentropy'\n",
    "    },\n",
    "    metrics=[AUC(),{'emotion_output': 'accuracy',\n",
    "             'sentiment_output': 'accuracy',\n",
    "             'toxicity_output': 'accuracy'}])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tf.Tensor(\n",
      "[[  101  2023  3185  2003  6429  1998  2039 26644  1012   102     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(1, 100), dtype=int32)\n",
      "Attention Mask: tf.Tensor(\n",
      "[[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 100), dtype=int32)\n",
      "Emotion Labels: tf.Tensor([[1. 0. 0. 0. 0. 0. 0.]], shape=(1, 7), dtype=float32)\n",
      "Sentiment Labels: tf.Tensor([[1. 0. 0.]], shape=(1, 3), dtype=float32)\n",
      "Toxicity Labels: tf.Tensor([[1. 0. 0. 0. 0. 0. 0.]], shape=(1, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = {\n",
    "    'text': [\n",
    "        \"I'm feeling happy today!\",\n",
    "        \"This movie is amazing and uplifting.\",\n",
    "        \"The weather is gloomy and sad.\",\n",
    "        \"The restaurant service was terrible.\",\n",
    "        \"I feel neutral about this book.\",\n",
    "        \"The speech was inspiring and motivational.\",\n",
    "        \"The internet trolls are spreading toxicity.\"\n",
    "    ],\n",
    "    'emotion': ['joy', 'joy', 'sadness', 'anger', 'neutral', 'joy', 'anger'],\n",
    "    'sentiment': ['positive', 'positive', 'negative', 'negative', 'neutral', 'positive', 'negative'],\n",
    "    'toxicity': [0, 0, 1, 1, 0, 0, 1]\n",
    "}\n",
    "\n",
    "emotions = ['joy', 'sadness','anger','neutral','surprise','fear']\n",
    "sentiments = ['positive','neutral','negative']\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Tokenize and encode the texts\n",
    "encoded_inputs = bert_tokenizer(df['text'].tolist(), padding='max_length', truncation=True,\n",
    "                                max_length=MAX_SEQ_LEN, return_tensors='tf')\n",
    "# Convert emotion labels to one-hot encoded vectors\n",
    "emotion_labels = np.array([emotions.index(label) for label in df['emotion']])\n",
    "emotion_labels = to_categorical(emotion_labels, num_classes=NUM_EMOTION_CLASSES)\n",
    "\n",
    "# Convert sentiment labels to one-hot encoded vectors\n",
    "sentiment_labels = np.array([sentiments.index(label) for label in df['sentiment']])\n",
    "sentiment_labels = to_categorical(sentiment_labels, num_classes=NUM_SENTIMENT_CLASSES)\n",
    "\n",
    "# Convert toxicity labels to one-hot encoded vectors\n",
    "toxicity_labels = to_categorical(df['toxicity'], num_classes=NUM_TOXICITY_CLASSES)\n",
    "\n",
    "# Create the sample dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((encoded_inputs['input_ids'],\n",
    "                                              encoded_inputs['attention_mask'],\n",
    "                                              emotion_labels,\n",
    "                                              sentiment_labels,\n",
    "                                              toxicity_labels))\n",
    "dataset = dataset.shuffle(len(df)).batch(1)  # Adjust batch size as needed\n",
    "\n",
    "# Print a sample batch from the dataset\n",
    "for batch in dataset.take(1):\n",
    "    input_ids, attention_mask, emotion_labels, sentiment_labels, toxicity_labels = batch\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Emotion Labels:\", emotion_labels)\n",
    "    print(\"Sentiment Labels:\", sentiment_labels)\n",
    "    print(\"Toxicity Labels:\", toxicity_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"e:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"e:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"e:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1047, in train_step\n        x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n    File \"e:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1775, in unpack_x_y_sample_weight\n        raise ValueError(error_msg)\n\n    ValueError: Data is expected to be in format `x`, `(x,)`, `(x, y)`, or `(x, y, sample_weight)`, found: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 100) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 100) dtype=int32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 7) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(None, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:4' shape=(None, 7) dtype=float32>)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# for epoch in range(10):\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#     for batch in dataset:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#         input_ids, attention_mask, emotion_labels, sentiment_labels, toxicity_labels = batch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#         model.train_on_batch([input_ids, attention_mask], [emotion_labels, sentiment_labels, toxicity_labels])\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model\u001b[39m.\u001b[39;49mfit(dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileruyoos__.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"e:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"e:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"e:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1047, in train_step\n        x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n    File \"e:\\Mini Projects\\Thesis\\report-system-back\\.venv\\Lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1775, in unpack_x_y_sample_weight\n        raise ValueError(error_msg)\n\n    ValueError: Data is expected to be in format `x`, `(x,)`, `(x, y)`, or `(x, y, sample_weight)`, found: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 100) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 100) dtype=int32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 7) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(None, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:4' shape=(None, 7) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "# for epoch in range(10):\n",
    "#     for batch in dataset:\n",
    "#         input_ids, attention_mask, emotion_labels, sentiment_labels, toxicity_labels = batch\n",
    "#         model.train_on_batch([input_ids, attention_mask], [emotion_labels, sentiment_labels, toxicity_labels])\n",
    "model.fit(dataset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m roc_curve, auc\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
